{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Image-based Experimental Modal Analysis\n",
    "\n",
    "**Klemen Zaletelj$^a$, Domen Gorjup$^a$ and Janko Slaviƒç$^a$\\***\n",
    "\n",
    "$^a$ Faculty of Mechanical Engineering, University of Ljubljana\n",
    "\n",
    "\\* Corresponding email: janko.slavic@fs.uni-lj.si\n",
    "\n",
    "www.ladisk.si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `github.com/ladisk/ImageBasedModalAnalysisTutorial`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Basic-experimental-skills\" data-toc-modified-id=\"Basic-experimental-skills-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Basic experimental skills</a></span><ul class=\"toc-item\"><li><span><a href=\"#Acquisition-parameters\" data-toc-modified-id=\"Acquisition-parameters-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Acquisition parameters</a></span></li><li><span><a href=\"#Lighting\" data-toc-modified-id=\"Lighting-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Lighting</a></span></li><li><span><a href=\"#Surface-preperation\" data-toc-modified-id=\"Surface-preperation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Surface preperation</a></span></li><li><span><a href=\"#Possible-errors\" data-toc-modified-id=\"Possible-errors-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Possible errors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Out-of-focus-image\" data-toc-modified-id=\"Out-of-focus-image-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Out of focus image</a></span></li><li><span><a href=\"#Improper-lighting\" data-toc-modified-id=\"Improper-lighting-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Improper lighting</a></span></li></ul></li></ul></li><li><span><a href=\"#Simplified-Optical-flow-Method\" data-toc-modified-id=\"Simplified-Optical-flow-Method-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Simplified Optical-flow Method</a></span></li><li><span><a href=\"#The-Lucas-Kanade-Method\" data-toc-modified-id=\"The-Lucas-Kanade-Method-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The Lucas-Kanade Method</a></span></li><li><span><a href=\"#Frequency-Response-Functions\" data-toc-modified-id=\"Frequency-Response-Functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Frequency Response Functions</a></span></li><li><span><a href=\"#Modal-Analysis---camera-data,-only\" data-toc-modified-id=\"Modal-Analysis---camera-data,-only-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modal Analysis - camera data, only</a></span></li><li><span><a href=\"#Modal-Analysis---Hybrid-method\" data-toc-modified-id=\"Modal-Analysis---Hybrid-method-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Modal Analysis - Hybrid method</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this tutorial, Anaconda and these additional packages must be installed:\n",
    "* ``pip install lvm_read``\n",
    "* ``pip install pyFRF``\n",
    "* ``pip install pyidi``\n",
    "* ``pip install pyEMA``\n",
    "\n",
    "Be sure to have the latest version of the avobe packages, use `pip install --upgrade package_name` if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from ipywidgets import interact\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import lvm_read\n",
    "import pyFRF\n",
    "import pyidi\n",
    "import pyEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some settings and functions that will be used during presentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "font_size = 15\n",
    "fig_size = (16.0, 8.0)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "matplotlib.rcParams['figure.figsize'] = fig_size\n",
    "matplotlib.rcParams['font.size'] = font_size\n",
    "\n",
    "\n",
    "def show_modal_data(nat_freq, damping):\n",
    "    \"\"\"Show modal data in a table-like structure.\"\"\"\n",
    "    print('   Nat. f.      Damping')\n",
    "    print(23*'-')\n",
    "    for i, f in enumerate(nat_freq):\n",
    "        print(f'{i+1}) {f:6.1f}\\t{damping[i]:5.4f}')\n",
    "        \n",
    "\n",
    "def plot_mode_shape(shape, axis, style='o-', frequency=None, **kwargs):\n",
    "    \"\"\"Plot a mode shape in a consistent fashion.\"\"\"\n",
    "    plot = axis.plot(shape / np.max(np.abs(shape)) * np.sign(shape[0]), \n",
    "                     style, **kwargs)\n",
    "    if frequency is not None:\n",
    "        axis.set_title(f'Mode shape - {frequency:.0f} Hz')\n",
    "    axis.set_yticks([])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic experimental skills\n",
    "**Experimental setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/experiment_setup.jpg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excitation with modal hammer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls loop src=\"figures/experiment.mp4\" width=\"100%\" rotate=\"270deg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of the selected files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_fname = 'data/camera.cih'\n",
    "lvm_fname = 'data/acceleration.lvm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the video using [pyidi][1] package, accessible on PyPI.\n",
    "\n",
    "[1]: https://github.com/ladisk/pyidi\n",
    "\n",
    "The package enables calculation of displacements and will be upgraded with additional functionalities.\n",
    "\n",
    "Currently only Photron's MRAW image file format is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = pyidi.pyIDI(cam_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are stored in the ``mraw`` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_image_nr = 175\n",
    "plt.imshow(video.mraw[sequential_image_nr], cmap='gray')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This example footage is for presentation purposes only and was made to be suitable for online sharing.*\n",
    "\n",
    "*Normaly image acquisation parameters such as frame rate and image resolution would be chosen as high as possible to obtain more precise results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls loop src=\"figures/video.MOV\" width=\"950\" rotate=\"270deg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that were used when recording can be found in the ``info`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lighting\n",
    "Lighting conditions are very important when using high-speed camera. To obtain optimal lighting conditions, a histogram of pixel intensity is viewed. An example of a well balanced historgram is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frame = 0\n",
    "x0 = 300 # position of observed rectangle\n",
    "y0, d = 9, 25\n",
    "roi = video.mraw[selected_frame, y0:y0+d, x0:x0+d]\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].imshow(video.mraw[selected_frame], cmap='gray')\n",
    "ax[1].hist(roi.flatten(), bins=50);\n",
    "# Formating\n",
    "ax[0].add_patch(patches.Rectangle((x0, y0), d, d, fill=False, color='r', linewidth=2))\n",
    "ax[0].grid(False)\n",
    "ax[1].set_xlabel('Grayscale value [/]')\n",
    "ax[1].set_ylabel('n pixels [/]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface preperation\n",
    "In order for gradient-based methods to work, sufficient gradient must be present on the images. Surface preperations is therefor necessary.\n",
    "\n",
    "Stripe pattern and random speckle pattern generation is implemented in the [speckle-pattern][1] python module. In this case, horizontal stripes were used.\n",
    "\n",
    "[1]: https://github.com/ladisk/speckle_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad0, grad1 = np.gradient(video.mraw[0].astype(float)) # gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 200 # position of cross section\n",
    "\n",
    "fig, ax = plt.subplots(2)\n",
    "ax[0].imshow(video.mraw[selected_frame], cmap='gray')\n",
    "ax[1].plot(video.mraw[selected_frame, :, x0], label='Grayscale value')\n",
    "ax[1].plot(grad0[:, x0], label='Gradient')\n",
    "# Formating\n",
    "ax[0].vlines(x0, 0, 40, colors='r', linewidth=3)\n",
    "ax[0].text(x0+10, -5, 'Cross section')\n",
    "ax[0].arrow(x0+50, 5, -35, 20, color='r', width=3)\n",
    "ax[0].grid(False)\n",
    "ax[1].set_xlabel('Image height [px]')\n",
    "ax[1].set_ylabel('Grayscale/gradient value [/]')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible errors\n",
    "\n",
    "#### Out of focus image\n",
    "The right side of the beam is in focus, while the left side is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_fname = r'data/focus.cih'\n",
    "video_layout = pyidi.pyIDI(layout_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(video_layout.mraw[0], 'gray')\n",
    "\n",
    "# Formating\n",
    "ax.grid(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improper lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_fname = r'data/illumination.cih'\n",
    "video_light = pyidi.pyIDI(light_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frame = 0\n",
    "y0, d = 9, 20\n",
    "\n",
    "def show(x0):\n",
    "    roi = video_light.mraw[selected_frame, y0:y0+d, x0:x0+d*2]\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].imshow(video_light.mraw[selected_frame], cmap='gray')\n",
    "    ax[1].hist(roi.flatten(), bins=50);\n",
    "    # Formating\n",
    "    ax[0].add_patch(patches.Rectangle((x0, y0), d*2, d, fill=False, color='r', linewidth=2))\n",
    "    ax[0].grid(False)\n",
    "    ax[1].set_xlabel('Grayscale value [/]')\n",
    "    ax[1].set_ylabel('n pixels [/]')\n",
    "    ax[1].set_xlim([0, 260])\n",
    "    plt.tight_layout()\n",
    "interact(show, x0=(75, 550, 50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified Optical-flow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic formulation:\n",
    "$$\n",
    "s(x_j,y_k,t)=\\frac{I_0(x_j,y_k)-I(x_j,y_k,t)}{|\\nabla I_0|}\n",
    "$$\n",
    "\n",
    "As used by [Javh et al.][1] ([pdf][2]).\n",
    "\n",
    "[1]: https://www.sciencedirect.com/science/article/pii/S0888327016304770\n",
    "[2]: http://lab.fs.uni-lj.si/ladisk/?what=abstract&ID=179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the reference image must be computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = np.average(video.mraw[:10], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and gradients in ``x`` (1) and ``y`` (0) directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad0, grad1 = np.gradient(reference_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points with the highest absolute value of gradient in **vertical** direction are determined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = 20\n",
    "border_h = 12\n",
    "n = 2\n",
    "N = 16\n",
    "w = np.arange(border, reference_image.shape[1]-border, np.abs(border - reference_image.shape[1]-border)//N)\n",
    "h = np.argsort(np.abs(grad0[border_h:-border_h, w]), axis=0)[-n:, :].T + border_h\n",
    "inds = np.column_stack((h.flatten(), w.repeat(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(grad0, cmap='gray')\n",
    "ax.scatter(inds[:, 1], inds[:, 0])\n",
    "ax.grid(False)\n",
    "ax.set_title('Gradient in $y$-direction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displacement computation, implemented in ``pyidi``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_points(points=inds) # setting points for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_method(method='sof',\n",
    "                mean_n_neighbours=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``get_displacements()`` method computes the displacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements = video.get_displacements() * 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(displacements[location, :, 0], label='Direction 0 (y)');\n",
    "ax.set_xlabel('Image [/]]')\n",
    "ax.set_ylabel('Displacement [m]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Lucas-Kanade Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By solving an overdetermined system of optical flow equations for a specified region of the image, 2D displacements of the subset can be calculated:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\begin{bmatrix}\n",
    "\t\t\\Delta x \\\\\n",
    "\t\t\\Delta y\n",
    "\t\\end{bmatrix} =\n",
    "\t\\begin{bmatrix}\n",
    "\t\t\\sum g_x^2 &\\sum  g_x \\, g_y \\\\\n",
    "\t\t\\sum  g_x \\, g_y &\\sum g_y^2\n",
    "\t\\end{bmatrix}^{-1}\n",
    "\t\\begin{bmatrix}\n",
    "\t\t\\sum g_x \\, (f-g) \\\\\n",
    "\t\t\\sum g_y \\, (f-g)\n",
    "\t\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$f(\\mathbf{x}) \\dots$ current (displaced) image\n",
    "\n",
    "$g(\\mathbf{x}) \\dots$ reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_lk = np.column_stack([np.ones_like(w)*video.info['Image Height']//2, w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.set_points(points_lk)\n",
    "video.set_method('lk', roi_size=(21, 23), max_nfev=10, int_order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_lk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video.show_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacements_lk = video.get_displacements(processes=2) * 8e-5 # this might take a minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements_lk = np.load('data/displacements_lk.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(displacements_lk[location, :, 0], label='Direction 0 (y)')\n",
    "ax.set_xlabel('Image [/]]')\n",
    "ax.set_ylabel('Displacement [m]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacements = displacements_lk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Response Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the FFT of displacement is computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(video.info['Total Frame'])\n",
    "dt = 1/int(video.info['Record Rate(fps)'])\n",
    "1/dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = dt*N\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_f_limit = 4000 # upper observed frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cam = np.fft.rfftfreq(N, dt)\n",
    "fft_cam = np.fft.rfft(displacements[:, :, 0], N) *2/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later the frequency range below `upper_f_limit` Hz is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_cam = np.copy(fft_cam[:, freq_cam<upper_f_limit])\n",
    "freq_cam = np.copy(freq_cam[freq_cam<upper_f_limit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FFT of force measurement is (also limited to `upper_f_limit`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvm = lvm_read.read(lvm_fname)\n",
    "force = lvm[0]['data'][:-30, 1] # 30 pre-samples\n",
    "N = len(force)//4 # the video was captured for 1/4 of a second\n",
    "dt = lvm[0]['Delta_X'][1]\n",
    "\n",
    "fft_force = np.fft.rfft(force, N) *2/N\n",
    "freq_force = np.fft.rfftfreq(N, dt)\n",
    "\n",
    "fft_force = np.copy(fft_force[freq_force<upper_f_limit])\n",
    "freq_force = np.copy(freq_force[freq_force<upper_f_limit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only one measurement was used, the FRF is determined by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frf_cam = fft_cam/fft_force "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(freq_cam, np.abs(frf_cam[location]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modal Analysis - camera data, only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modal analysis can be made using ``pyEMA`` package, accessible on [PyPI][1].\n",
    "\n",
    "[1]: https://pypi.org/project/pyEMA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = pyEMA.Model(frf_cam, freq_cam, pol_order_high=50, upper=upper_f_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poles are computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.get_poles(show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stable poles can be picked in the stability chart, or preditermind by passing in approximate natural frequencies (picking poles works only in the interactive mode, use magic command: %matplotlib qt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.stab_chart(cam.all_poles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.print_modal_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the stable poles are determind, a ``lsfd`` method can be called to reconstruct the FRF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frf_rec, shapes_cam = cam.get_constants(FRF_ind='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(freq_cam, np.abs(frf_cam[location]), label='Camera FRF', alpha=0.8)\n",
    "ax.semilogy(freq_cam[:-1], np.abs(frf_rec[location]), label='Reconstructed FRF', lw=2)\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('Receptance')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(shapes_cam.shape[1])\n",
    "for i, a in enumerate(ax):\n",
    "    plot_mode_shape(shapes_cam[:, i], axis=a, frequency=cam.nat_freq[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modal Analysis - Hybrid method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hybrid method was developed by Javh et al. Further details can be found [here][1] ([pdf][2])\n",
    "\n",
    "First, the acceleration and force data are needed:\n",
    "\n",
    "[1]: https://www.sciencedirect.com/science/article/pii/S0888327017302637\n",
    "[2]: http://lab.fs.uni-lj.si/ladisk/?what=abstract&ID=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyb_acc = lvm[0]['data'][:-30, 0] * 9.81 # acceleration data (converted to m/s**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FRF can be computed using ``pyFRF`` package, accessible on [PyPI][1].\n",
    "\n",
    "[1]: https://pypi.org/project/pyFRF/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyFRF\n",
    "\n",
    "frf_ = pyFRF.FRF(\n",
    "    sampling_freq=1/dt,\n",
    "    exc=force,\n",
    "    resp=hyb_acc,\n",
    "    exc_window='None',\n",
    "    resp_type='a',\n",
    "    resp_window='None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the frequencies lower than `upper_f_limit` Hz are observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_acc = frf_.get_f_axis()\n",
    "frf_acc = frf_.get_FRF(form='receptance')\n",
    "\n",
    "frf_acc = frf_acc[freq_acc<upper_f_limit]\n",
    "freq_acc = freq_acc[freq_acc<upper_f_limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location of acceleration measurement is at identified camera point with index 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(freq_cam, np.abs(frf_cam[location]), label='Camera FRF')\n",
    "ax.semilogy(freq_acc, np.abs(frf_acc), label='Accelerometer FRF')\n",
    "ax.set_title('Camera-based response at accelerometer location')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the ``lscf`` object can be created and poles are computed for the hybrid method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pyEMA.Model(frf_acc[1:], freq_acc[1:], pol_order_high=50, upper=upper_f_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.get_poles(show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.stab_chart(acc.all_poles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.print_modal_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poles computed based on accleration data are more reliable. These poles can now be used in reconstruction of FRFs from camera. A new ``lscf`` object is made with camera FRF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_hyb = pyEMA.Model(frf_cam, freq_cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the reconstruction is done using accleration-determined poles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frf_hyb, shapes_hybrid = cam_hyb.get_constants(whose_poles=acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(freq_cam, np.abs(frf_cam[location]), label='Camera FRF', alpha=0.8)\n",
    "ax.semilogy(freq_acc, np.abs(frf_acc), label='Accelerometer FRF')\n",
    "ax.semilogy(freq_cam[:-1], np.abs(frf_hyb[location]), label='Reconstructed FRF', lw=3)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(shapes_cam.shape[-1])\n",
    "for i, a in enumerate(ax):\n",
    "    cam_freq = cam.nat_freq[i]\n",
    "    hybrid_f_index = np.argmin(np.abs(acc.nat_freq - cam_freq))\n",
    "    plot_mode_shape(shapes_hybrid[:, hybrid_f_index], axis=a, \n",
    "                    frequency=acc.nat_freq[hybrid_f_index], lw=2, label='Hybrid')\n",
    "    plot_mode_shape(shapes_cam[:, i], axis=a , alpha=0.3, label='Camera')\n",
    "    a.set_yticks([])\n",
    "ax[0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(fig_size[0], fig_size[1]/3))\n",
    "plot_mode_shape(shapes_hybrid[:, -1], axis=plt.gca(), \n",
    "                frequency=acc.nat_freq[-1], lw=2, label='Hybrid')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.ladisk.si/imageEMASummer.php\"><img src=\"figures/Summer School on High-speed Image Based Experimental Modal Analysis & Open Source Tools.png\" width=\"90%\"></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "259px",
    "width": "276px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
